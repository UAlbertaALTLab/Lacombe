# Applying OCR to Lacombe's _Dictionnaire de la langue des Cris_ (1874)

This project uses the optical character recognition (OCR) tool [Tesseract][Tesseract] to extract text from Albert S. Lacombe's (1874) _Dictionnaire de la langue des Cris_ and convert it into a useable database following the [Data Format for Digital Linguistics][DaFoDiL] (DaFoDiL).

## Contents

<!-- TOC -->

- [Scans](#scans)
- [Text Versions](#text-versions)
- [OCR Results](#ocr-results)
- [Comparing OCR Outputs](#comparing-ocr-outputs)
- [Calculating OCR Accuracy](#calculating-ocr-accuracy)
- [Accuracy Reports](#accuracy-reports)
- [Notes on Gold Standard Transcriptions](#notes-on-gold-standard-transcriptions)

<!-- /TOC -->

## Scans

We have high-quality scans available from the following sources:

* [John Carter Brown Library](https://archive.org/details/dictionnairedela01laco) (color; 98 MB; `Carter.pdf`)
* U.S. Library of Congress (83 MB; `LOC.pdf`)
* [Oxford](https://archive.org/details/dictionnairedel00lacogoog) (B&W, from microfilm; 44 MB; `Oxford.pdf`)
* [Bibliothèque et Archives Nationales du Québec](https://numerique.banq.qc.ca/patrimoine/details/52327/3994014) (915 MB; `Quebec.pdf`)
* [Peel Library](https://drive.google.com/drive/folders/1AtauHmz8qh_Bfp0YvyZsGhb9IioeiTSl) (individual pages, B&W, from microfilm, .tif format; `Peel.pdf`)

## Text Versions

Aside from the OCR'd text version of Lacombe that we ourselves are producing, the following text versions also exist for the Lacombe dictionary. All of these are located in the `OCR/` folder.

* [John Carter Brown Library](./OCR/Brown/full.txt)
* [U.S. Library of Congress](./OCR/LOC/full.txt)
* [Oxford](./OCR/Oxford/full.txt)
* [Peel](./OCR/Peel/full.txt)
* [Quebec](./OCR/Quebec/full.txt)

The version from the Bibliothèque et Archives Nationales du Québec is by far the highest-quality scan available, so this is the scan we are using for our own OCR process.

## OCR Results

This section discusses the results we achieved from running Tesseract on the Quebec scans ourselves.

We obtained the following results using Tesseract 5.0. Consult the [Tesseract documentation][Tesseract] for the meaning of the various command line options. Click the **link** in the **Report** column to see the accuracy report for that particular set of Tesseract options. See the [Accuracy](#accuracy) section below for more details on how to read the accuracy reports.

Options    | Accuracy | Report
-----------|---------:|:-------------------------------:
no options |   90.41% | [link](./OCR/Quebec/reports/no-options.txt)

## Comparing OCR Outputs

This section compares the OCR text outputs for the different scans.

It was decided up front that the text version of the Oxford scans is too poor quality to be usable:

> for some reason or another, large sections of some pages seem to be missing, or at least thrown out of order in a such a way as to make them almost impossible to find, a fact not helped by the generally poor quality of the text. In any case, I made the judgement that if it was this difficult to even distinguish pages in the Oxford OCR, it was probably reasonable to assume that its contents cannot be used. (@DBDacanay)

Source | Accuracy |               Report
-------|---------:|:---------------------------------:
Brown  |   85.86% | [report](./OCR/Brown/accuracy.txt)
LOC    |   87.96% |  [report](./OCR/LOC/accuracy.txt)
Peel   |   60.79% | [report](./OCR/Peel/accuracy.txt)

## Calculating OCR Accuracy

The accuracy of the OCR results was compared against the manually-transcribed gold standard files (located in `OCR/standard/`) using the [ocreval][ocreval] library (by @eddieantonio). For each set of options, an accuracy report was produced using ocreval and saved in `OCR/Quebec/reports/`. See the [ocreval user guide](./ocreval-user-guide.pdf) (specifically §2.1) for details concerning how to read the accuracy report.

To run the accuracy report, first install [ocreval][ocreval]. Then run the following command:

```
accuracy <OCR output> <gold standard> [out file]
```

The `accuracy` script takes the following 3 arguments:

1. `<OCR output>`: the output generated by the OCR engine
2. `<gold standard>`: the gold standard / source of truth for the text being evaluated
3. `[out file]`: [optional] the location where the accuracy report should be saved

To combine multiple pages of OCR output or gold standard together for aggregated comparison of multiple pages at once, first make sure you have [Node and npm][Node] installed, then run the following command (where `<directory>` is the path to a folder containing text files you would like to concatenate together, and `<outfile>` is the path to the file where you would like the results saved). This script will only combine files with a `.txt` extension. You can then run ocreval on the combined file.

`node lib/concat.js <directory> <outfile>`

You can also concatenate both the `OCR/standard/sample/` and `OCR/Quebec/sample` folders with a single command, `npm run concat`. This will create `OCR/standard/sample.txt` and `OCR/Quebec/sample.txt` files for comparison.

Finally, you can run ocreval on these two combined files with `npm run accuracy`. This will create an accuracy report titled `accuracy.txt` in the project root.

## Accuracy Reports

The first section of the accuracy report contains general statistics:

* `Characters`: The number of characters in the gold standard.
* `Errors`: The number of character errors.
* `Accuracy`: The overall accuracy percentage.

There are 3 types of errors, summarized in the third section of the accuracy report:

* `Ins`: insertion errors
* `Subst`: substitution errors
* `Del`: deletion errors

The fourth section of the report shows accuracy by character class.

The fifth section of the report lists all the errors types, sorted largest to smallest by number of times each error occurs. The number of errors of each type can be divided by the edit distance between the correct and generated forms to count the number of times this error occurred.

The sixth section of the report lists each character in the gold standard, the number of times that character was missed by the OCR, and the overall accuracy for that character.

## Notes on Gold Standard Transcriptions

The following conventions help improve the reliability of the accuracy report:

* The gold standard must have hard-coded line breaks. Adding line breaks improved the accuracy score by 5%.
* The gold standard must have hyphens whenever the original text has hyphens. (These were added with the line breaks.)
* The gold standard must be NFC normalized. (This was already done in @DBDacanay's original.)
* The gold standard must have leading guillemets (`«`) and/or crosses (`x`). Adding these improved the accuracy score by 2.09%.

<!-- LINKS -->

[DaFoDiL]:   https://format.digitallinguistics.io
[Node]:      https://nodejs.org/en/
[ocreval]:   https://github.com/eddieantonio/ocreval
[Tesseract]: https://github.com/tesseract-ocr/tesseract
